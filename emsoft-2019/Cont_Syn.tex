\section{Controller Synthesis}
\eva{How we actually get the controller, including feedback loop and mixed-precision tuning}
In this work we present an innovative method for the off-line design (explicit) of robust MPC controllers for linear time invariant systems.

In formula (\ref{eq:epsilontot}), the equation for $\varepsilon$ contains: $\varepsilon_{A/D}$ that is the error introduced by the analog-digital conversion, and $\varepsilon_{Q}$ that is generated by the quantization of hyperplanes $H\statevar<=K$ in a finite number of bits.
This $\varepsilon_{Q}$ can be tuned based on memory availability in the micro-controller.
The rule for $\varepsilon_{Q}$ is the following:
\begin{equation}\label{eq:quantizationlines}
\varepsilon_{Q} > (H-\hat{H}_{p})\qstatevar+(K-\hat{K}_{p})
\end{equation}
This inequality assures that the distance between any hyperplane represented in infinite precision (H and K), and its counter-part quantized in p bits ($(\hat{H})_{p}$ and $(\hat{K})_{p}$), is bounded by $\varepsilon_{Q}$. 

Our goal is to solve (\ref{eq:quantizationlines}) with respect to p: assign an arbitrary value to $\varepsilon_{Q}$ and find the minimal-precision p such that the inequality holds.

The main advantage in this approach (compared to fixing the precision p a priori), is that the value of p can be tuned based on the memory availability in the micro-controller.

To solve (\ref{eq:quantizationlines}) we used Daisy: a static analyzer for finite precision expressions, ables to provide a sound upper-bound to the maximal approximation error of a formula with respect to its real (infinite precision) counterpart. Since the magnitude of the round-off error depends on the range of input variables, any variable encoded in Daisy has to be bounded. 

Since the state variable \statevarmath is bounded by \statespace, and F,G,H, and K are vectors of constants, we can rely on Daisy for this verification step.

In a similar way, we use Daisy to solve the inequality in (\ref{eq:delta}) with respect to p:
\begin{flalign}
\label{eq:deltaminusmax}
&delta - \Big(\max_{\forall i,j\;|\;neighbour(i,j)}|u_{i}-u_{j}|\Big)>=\\
& \max_{\forall\;\regionimath{i}\;in\;\statespace} err(u_{i})_{p}\nonumber
\end{flalign}

Be aware that the left side of the inequality is not parametrized in p. Only the right size of (\ref{eq:deltaminusmax}) actually depends on the precision p. After we come up with a numerical value for the left side of the inequality, we encode (\ref{eq:deltaminusmax}) in Daisy in the same way done for (\ref{eq:quantizationlines}).

\subsection{Algorithm}

\begin{lstlisting}[language=Python,numbers=left,numbersep=3pt,frame=lines,keepspaces=true,escapeinside={(*}{*)},caption=design of robust MPC with verification and precision tuning,label={lst:alg}]
delta=input()
(*$\varepsilon_{Q}$*)=input()
assert (delta>=0 and (*$\varepsilon_{Q}$*)>0)
(*$\varepsilon$*)=(*$\varepsilon_{A/D}$*)+(*$\varepsilon_{Q}$*)

while True:
design_robust_MPC(delta)
maxUij = compute (*(\ref{eq:maximization})*) with size(tube)=(*$\varepsilon$*)
if delta > maxUij:
max_err=delta-maxUij
UNI_MIX_precision(F,G,max_err)
UNI_MIX_precision(H,K,(*$\varepsilon_{Q}$*))
break
else:
delta=maxUij+(*$\varepsilon_{SAFE}$*)
\end{lstlisting}
In Listing \ref{lst:alg} we describe the procedure used to design a robust MPC controller such that (\ref{eq:delta}) is respected.

First, the designer fixes the initial values for delta and $\varepsilon_{Q}$.

Even if it possible to assign value zero to delta~\cite{imperialrmpc}, we do not encourage such initialization value: it is going to fail the analysis (at least) for the first iteration because the error in (\ref{eq:maxfperror}) is going to be greater than zero (in the remote scenario where  (\ref{eq:maximization}) is equal to zero). A better initialization would be to set delta to an arbitrary small value, slightly greater than zero.

On the other hand, the value for $\varepsilon_{Q}$ has to be strictly greater than zero, otherwise we could rely on infinite precision for p in (\ref{eq:quantizationlines}).

Once input parameters are verified, we use MATLAB toolbox to design a controller with robustness value equal to delta. 

Then, we compute (\ref{eq:maximization}) and we compare the result with delta: we are aware that the computation of (\ref{eq:maximization}) is not exact (even if it is done in 64bits precision), but usually the computation of (\ref{eq:maximization}) results in a value that is several orders of magnitude greater than the error of the computation itself. For this reason we consider this approximation error negligible from the point of view of our analysis. 

Again, in the conditional inside the loop, delta has to be strictly greater than \texttt{maxUij} otherwise we do not have space for computing the precision for (\ref{eq:deltaminusmax}).

In case the conditional statement is verified,
the precision tuning phase starts.
For the precision tuning of activation functions, we allow an error that is bounded by \texttt{max\_err}. This is exactly what is described in (\ref{eq:deltaminusmax}).

On the other hand, the quantization of polytopes borders (the region bounds in \statespace) can produce an error that is at most $\varepsilon_{Q}$, in this way we satisfy 
(\ref{eq:quantizationlines}).

In case the conditional fails and \texttt{maxUij} is greater than (or equal to) delta, the controller needs to be re-designed with a robustness value that is at least equal to the current value of \texttt{maxUij}. The same consideration done for the initialization of input parameters holds also here: the constant $\varepsilon_{SAFE}$ is used to relax the value for delta, to a value slightly greater than \texttt{maxUij}. In this way, we aim to give some space to the precision tuning phase in the next iteration of the loop. Otherwise, in case $\varepsilon_{SAFE}$ is equal to zero, the next iteration of the precision tuning phase is going to require unnecessarily wide precision value for p, usually greater than 32 bits. 
We remark that the point of the analysis is to find a low precision configuration for bounds and activation functions: in case the analysis outputs a precision greater than 32bits, we fail in our goal.
Then, with a minimal alteration to the upper bound of delta, we sensibly reduce the precision needed for $F$ and $G$, with respect to the standard 32 bits precision.


