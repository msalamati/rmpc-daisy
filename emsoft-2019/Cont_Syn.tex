\section{Controller Synthesis}
\eva{How we actually get the controller, including feedback loop and mixed-precision tuning}
%In this work we present an innovative method for the off-line design (explicit) of robust MPC controllers for linear time invariant systems.
We need to solve the two inequalities in (\ref{eq:delta}) (\ref{eq:quantizationlines}) in order to build a controller with guarantees of robustness.
%The equation for $\varepsilon$ in (\ref{eq:epsilontot}),  contains: $\varepsilon_{A/D}$ that is the error introduced by the analog-digital conversion, and $\varepsilon_{Q}$ that is the error generated from the quantization of hyperplanes $\mathcal{R}$ in a finite number of bits.
%This $\varepsilon_{Q}$ can be tuned based on memory availability in the micro-controller.
%The rule for $\varepsilon_{Q}$ is the following:
%\begin{equation}\label{eq:quantizationlines}
%\varepsilon_{Q} > (H-\hat{H}_{p})\qstatevar+(K-\hat{K}_{p})
%\end{equation}
%This inequality assures that the distance between any hyperplane represented in infinite precision (H and K), and its counter-part quantized in p bits ($(\hat{H})_{p}$ and $(\hat{K})_{p}$), is bounded by $\varepsilon_{Q}$. 
We use Daisy to solve inequality (\ref{eq:quantizationlines}) with respect to p: we assign an arbitrary value to $\varepsilon_{Q}$ and find the minimal-precision p such that the inequality holds. The main advantage of using this approach (compared to fixing the precision p a priori), is that the value for $\varepsilon_{Q}$ can be regulated based on micro-controller specifications (e.g. memory availability).
%To solve (\ref{eq:quantizationlines}) we used Daisy: a static analyzer for finite precision expressions, ables to provide a sound upper-bound to the maximal approximation error of a formula with respect to its real (infinite precision) counterpart. Since the magnitude of the round-off error depends on the range of input variables, any variable encoded in Daisy has to be bounded.
In a similar way, we solve the inequality in (\ref{eq:delta}) with respect to p:
\begin{flalign}
\label{eq:deltaminusmax}
&delta - \Big(\max_{\forall i,j\;|\;neighbour(i,j)}|u_{i}-u_{j}|\Big)>=\\
& \max_{\forall\;\regionimath{i}\;in\;\statespace} err(u_{i})_{p}\nonumber
\end{flalign}

Be aware that the left side of (\ref{eq:deltaminusmax}) is not parametrized in p (it is a plain number). Only the right size of (\ref{eq:deltaminusmax}) actually depends on the precision p. We compute the left side of the inequality using large enough precision p (e.g. 64 bits) such that we can safely ignore the error resulting from the computation.
Then, we encode (\ref{eq:deltaminusmax}) in Daisy to detect precision p. Note that p used to solve (\ref{eq:quantizationlines}) can be different from $p'$ used to solve (\ref{eq:deltaminusmax}).

\subsection{Algorithm}
In Listing \ref{lst:alg} we describe the procedure used to design a robust MPC controller such that (\ref{eq:deltaminusmax}) is satisfied.

\begin{lstlisting}[language=Python,numbers=left,numbersep=3pt,frame=lines,keepspaces=true,escapeinside={(*}{*)},caption=design of robust MPC with precision tuning,label={lst:alg}]
 delta = input()
 (*$\varepsilon_{Q}$*) = input()
 assert (delta >= 0 and (*$\varepsilon_{Q}$*) > 0)
 (*$\varepsilon$*) = (*$\varepsilon_{A/D}$*) + (*$\varepsilon_{Q}$*)

 while True:
   (*\maxUij*) = design_robust_MPC(delta, (*$\varepsilon$*))
   if delta > (*\maxUij*):
     (*$err_{max}(u_{i})_{p}$*) = delta-(*\maxUij*)
     UNI_MIX_precision(F, G, (*$err_{max}(u_{i})_{p}$*))
     UNI_MIX_precision(H, K, (*$\varepsilon_{Q}$*))
     break
   else:
     delta=(*\maxUij*)+(*$\varepsilon_{SAFE}$*)
\end{lstlisting}

First, the designer of the controller provides the initial values for delta and $\varepsilon_{Q}$. Even if it possible to assign value zero to delta~\cite{imperialrmpc}, we do not encourage such initialization value: it is going to fail the analysis (at least) for the first iteration, because the error in (\ref{eq:maxfperror}) is going to be greater than zero. A better initialization would be to set delta to an arbitrary small value, slightly greater than zero.

On the other hand, the value for $\varepsilon_{Q}$ has to be strictly greater than zero, otherwise we could rely on infinite precision for p in (\ref{eq:quantizationlines}).

Once input parameters are verified, we design the controller in MATLAB. 

We compute (\ref{eq:maximization}) and we compare the result with delta. Again, in the conditional inside the loop, delta has to be strictly greater than \maxUij\space otherwise we do not have space for computing the precision for (\ref{eq:deltaminusmax}). In case the conditional is true,
the precision tuning phase starts.
For the precision tuning of activation functions, we allow an error that is bounded by the left side of inequality (\autoref{eq:deltaminusmax}). While for the quantization of hyperplanes the error bound is $\varepsilon_{Q}$.

In case the conditional fails and \maxUij is greater than or equal to delta, the controller needs to be re-designed with a robustness value that is at least equal to the current value of \maxUij. The same suggestion for input parameters holds also here: the constant $\varepsilon_{SAFE}$ is used to relax the value for delta, to a value slightly greater than \maxUij. In this way, we relax the constraint used in the next iteration of precision tuning. Otherwise, in case $\varepsilon_{SAFE}$ is equal to zero, the next iteration of the loop is going to predict unnecessarily wide precision value for p, usually greater than 32 bits. 