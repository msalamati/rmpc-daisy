%
% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf]{acmart}
\usepackage{listings}
\usepackage{multirow}
\usepackage{lscape}
\usepackage{amsmath}

%
% defining the \BibTeX command - from Oren Patashnik's original BibTeX documentation.
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08emT\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\newcommand{\statevar}{x_{k}}
\newcommand{\statevarmath}{$x_{k}\,$}
\newcommand{\qstatevar}{\hat{x}_{k}}
\newcommand{\qstatevarmath}{$\hat{x}_{k}\,$}
\newcommand{\statespace}{X}
\newcommand{\regioni}[1]{$X_{{#1}}$}
\newcommand{\regionimath}[1]{X_{{#1}}}
% Rights management information. 
% This information is sent to you when you complete the rights form.
% These commands have SAMPLE values in them; it is your responsibility as an author to replace
% the commands and values with those provided to you when you complete the rights form.
%
% These commands are for a PROCEEDINGS abstract or paper.
\copyrightyear{2018}
\acmYear{2018}
\setcopyright{acmlicensed}
\acmConference[Woodstock '18]{Woodstock '18: ACM Symposium on Neural Gaze Detection}{June 03--05, 2018}{Woodstock, NY}
\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection, June 03--05, 2018, Woodstock, NY}
\acmPrice{15.00}
\acmDOI{10.1145/1122445.1122456}
\acmISBN{978-1-4503-9999-9/18/06}

%
% These commands are for a JOURNAL article.
%\setcopyright{acmcopyright}
%\acmJournal{TOG}
%\acmYear{2018}\acmVolume{37}\acmNumber{4}\acmArticle{111}\acmMonth{8}
%\acmDOI{10.1145/1122445.1122456}

%
% Submission ID. 
% Use this when submitting an article to a sponsored event. You'll receive a unique submission ID from the organizers
% of the event, and this ID should be used as the parameter to this command.
%\acmSubmissionID{123-A56-BU3}

%
% The majority of ACM publications use numbered citations and references. If you are preparing content for an event
% sponsored by ACM SIGGRAPH, you must use the "author year" style of citations and references. Uncommenting
% the next command will enable that style.
%\citestyle{acmauthoryear}

%
% end of the preamble, start of the body of the document source.
\begin{document}

%
% The "title" command has an optional parameter, allowing the author to define a "short title" to be used in page headers.
\title{The Name of the Title is Hope}

%
% The "author" command and its associated commands are used to define the authors and their affiliations.
% Of note is the shared affiliation of the first two authors, and the "authornote" and "authornotemark" commands
% used to denote shared contribution to the research.
\author{Ben Trovato}
\authornote{Both authors contributed equally to this research.}
\email{trovato@corporation.com}
\orcid{1234-5678-9012}
\author{G.K.M. Tobin}
\authornotemark[1]
\email{webmaster@marysville-ohio.com}
\affiliation{%
  \institution{Institute for Clarity in Documentation}
  \streetaddress{P.O. Box 1212}
  \city{Dublin}
  \state{Ohio}
  \postcode{43017-6221}
}

\author{Lars Th{\o}rv{\"a}ld}
\affiliation{%
  \institution{The Th{\o}rv{\"a}ld Group}
  \streetaddress{1 Th{\o}rv{\"a}ld Circle}
  \city{Hekla}
  \country{Iceland}}
\email{larst@affiliation.org}

\author{Valerie B\'eranger}
\affiliation{%
  \institution{Inria Paris-Rocquencourt}
  \city{Rocquencourt}
  \country{France}
}

\author{Aparna Patel}
\affiliation{%
 \institution{Rajiv Gandhi University}
 \streetaddress{Rono-Hills}
 \city{Doimukh}
 \state{Arunachal Pradesh}
 \country{India}}


%
% By default, the full list of authors will be used in the page headers. Often, this list is too long, and will overlap
% other information printed in the page headers. This command allows the author to define a more concise list
% of authors' names for this purpose.
\renewcommand{\shortauthors}{Trovato and Tobin, et al.}

%
% The abstract is a short summary of the work to be presented in the article.
\begin{abstract}

\end{abstract}

%
% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
% Please copy and paste the code instead of the example below.
%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}

%
% Keywords. The author(s) should pick words that accurately describe the work being
% presented. Separate the keywords with commas.
\keywords{datasets, neural networks, gaze detection, text tagging}
%\keywords{datasets, neural networks, gaze detection, text tagging}

%
% A "teaser" image appears between the author and affiliation information and the body 
% of the document, and typically spans the page. 
%\begin{teaserfigure}
%  \includegraphics[width=\textwidth]{sampleteaser}
%  \caption{Seattle Mariners at Spring Training, 2010.}
%  \Description{Enjoying the baseball game from the third-base seats. Ichiro Suzuki preparing to bat.}
%  \label{fig:teaser}
%\end{teaserfigure}

%
% This command processes the author and affiliation and title information and builds
% the first part of the formatted document.
\maketitle

\section{Introduction}
\section{Background}
\section{Problem Description}
In this work we present an innovative method for the off-line design of robust MPC controllers (explicit), for linear time invariant systems.

To guarantee stability of the system at runtime, at design time the designer specifies the maximal disturbance value the system can tolerate: we call this numeric value \texttt{delta}. This delta has to be an upper bound for both errors generated by the system itself (e.g. noise from sensors) and disturbance coming from sources external to the system (e.g. friction).

The system is then designed to be robust against a maximal disturbance of value \texttt{delta}.

Among the sources of disturbance targeting the controller, our goal is to assure that the approximation error caused by the use of finite precision arithmetic is also bounded by this design value \texttt{delta}.

In particular, (i) first we want to guarantee that the finite precision implementation of the controller produces an approximation error that is at most equal to delta.

(ii) Second, we want to take advantage of this disturbance delta, and reduce the arithmetic precision used for computations and storage, while still guarantee that the approximation error generated is bounded by delta. Our intuition is that a greater value for delta allows for a reduced precision for computations (e.g. with respect to 32bits).

Given an initial delta, we design the controller by solving an off-line optimization problem. We rely on MATLAB multi-parametric toolbox to solve such optimization problem~\cite{matlabMPT, matlabYALMIP}. 
The output of the suite is a continuous piecewise affine (PWA) function, together with a partitioning of the domain of \statevarmath. Each element in this partitioning is called a region.
A generic region $i$ consists in a n-polytope, uniquely identified by a set of inequalities $H_{i}\statevar<=K_{i}$. 

We call \statespace\space the union of all regions $i$ is the domain of the state variable $x_{k}$:
\begin{equation}
\statespace = \bigcup_{i}(H_{i}\statevar<=K_{i})
\end{equation}

Each region $i$ is associated with an activation function $u_{i,k}=F_{i}x_{k}+G_{i}$.

%https://en.wikipedia.org/wiki/Polyhedron
%https://en.wikipedia.org/wiki/Polytope

A drawback in the design of explicit MPC is that both regions boundaries (H and K) and activation functions (F and G), have to be stored on the micro-controller. Usually these devices have limited memory in the order of KBs.

At runtime, the value of state variable \statevarmath  is compared against the polytopes bounds stored on the device: depending on the region containing \statevarmath, the corresponding activation function is computed.

This work does not rely on any specific technique to verify which region \statevarmath belongs to, so we consider a linear search over all the regions in \statespace\space, using a case-of conditional statement similar to the one in Listing \ref{lst:caseof}.

\begin{lstlisting}[escapeinside={(*}{*)},label={lst:caseof}, caption=switch for region selection]
switch((*\statevarmath*)):
  case (*$ H_{1}\statevar<=K_{1}$*) then (*$u_{1}$*)
  case (*$ H_{2}\statevar<=K_{2}$*) then (*$u_{2}$*)
  case (*$ H_{3}\statevar<=K_{3}$*) then (*$u_{3}$*)
  ...
  case (*$ H_{n}\statevar<=K_{n}$*) then (*$u_{n}$*)
\end{lstlisting}

\section{Error Analysis}
Since (i) any measurement of the plant comes with some uncertainty (e.g. uncertainty from sensors) but also (ii) due to analog-digital conversion, the value of state variable \statevarmath comes with some numerical errors. The equation for \statevarmath is than defined as:
\begin{equation}
\qstatevar=\statevar + \texttt{err}
\end{equation}
where \statevarmath is the true (unknown) measure of the plant, while \qstatevarmath is the actual value.

\texttt{err} generates instability when it is time to verify which region \qstatevarmath belongs to: given the value of \statevarmath the region should be $i$, but because of \texttt{err}, actually region $j$ is selected. This scenario becomes more intuitive when \qstatevarmath falls \texttt{close} to the border between two generic regions $i$ and $j$, but in general it depends on the magnitude of \texttt{err}.

Assuming that all points in region $i$ might be erroneously assigned to region $j$, without any  knowledge of the actual value of error \texttt{err}, is a too wide over-approximation of the existing instability. 

Our goal is to build a feasible geometrical space around the border between regions $i$ and $j$, where actually it is feasible that \statevarmath belongs to region $i$ but \qstatevarmath follows in region $j$.

We call this geometrical space the \texttt{tube}.

There are two main sources of error affecting the size of the \texttt{tube}: (i) the first one is caused by analog-digital conversion, happening just before the controller receives an estimation of the plant from the sensors. We call this error $\varepsilon_{A/D}$: 

\begin{equation}\nonumber
\varepsilon_{A/D}=\frac{V_{cc}}{2^{p}-1}
\end{equation}

Where $V_{cc}$ is the reference voltage of the converter (e.g. typical 5V) and $p$ represents the number of bit of the processor.

The second error affecting the size of the \texttt{tube} is caused by (ii) the quantization of region bounds in the memory of the micro-controller. We call this error $\varepsilon_{Q}$ for error quantization.

While $\varepsilon_{A/D}$ is intrinsic in the capabilities of the device, $\varepsilon_{Q}$ depends on the precision used to store the boundaries. This second error can be regulated based on a trade-off among accuracy of the storage and memory save.

The total size of the \texttt{tube} is then:
\begin{equation}\label{eq:epsilontot}
\varepsilon=\varepsilon_{A/D}+\varepsilon_{Q}
\end{equation}
\section{Finite Precision Implementation}
The output of the controller can be affected by two main errors: (i) the first one happens when the controller chooses the wrong activation function because of $\varepsilon$ in (\ref{eq:epsilontot}), while the second one (ii) is the approximation error deriving from the finite precision arithmetic used to compute the activation function itself.
 
The effect of selecting the wrong activation function are the same as instability in the conditional switch reported in Listing \ref{lst:caseof}: suppose an hypothetic scenario where all the measurements were done in infinite precision and without any uncertainty, the controller $i$ would be activated, but because of these limitations actually $j$ is selected. The resulting error is then the difference between the two branches $i$ and $j$ in Listing \ref{lst:caseof}.

The system has to be robust against a mistake in choosing controller $i$ instead of $j$ only when \qstatevarmath falls into the \texttt{tube} between $i$ and $j$, and not for all the points in the two regions.

In the following, we assume $i$ and $j$ are the index of two generic regions in \statespace:

%\begin{equation}
\begin{flalign}
\label{eq:maximization}
&\max_{\forall i,j\;|\;neighbour(i,j)}|u_{i}-u_{j}| = \\
&\max_{\forall i,j\;|\;neighbour(i,j)}|F_{i}\statevar+G_{i} - (F_{j}\statevar+G_{j})|
\end{flalign}
%\end{equation}

Because of the linearity of the function $U_{i}-U_{j}$, and because of the convexity of regions $i$, $j$ it is enough to evaluate function (\ref{eq:maximization}) at the corners of the \texttt{tube}.

%The geometrical space where $\hat{X}$ activates $U_{i}$, while X would activate $U_{j}$ can be bounded thanks to a preliminary knowledge of the error $\varepsilon$: the distance between region $i$ and $j$ such that:
%\begin{equation}
%\hat{X}-X <= \varepsilon
%\end{equation}
%and $\hat{X}$ belongs to region $i$ but $X$ to $j$ (or vice-versa).

We compute (\ref{eq:maximization}) for all pairs of neighbor regions $i$ and $j$. Two regions are neighbors when they share at least a border.

In formula $\exists\; m,n \;$such that:
\begin{equation}
(H_{i}\statevar-K_{j})_{m} = (H_{j}\statevar-K_{j})_{n}
\end{equation}
where $m$ and $n$ are the index of the two matching borders. We label $border_{i,j}$ the matching border shared among the two regions.

Starting from the equation of $border_{i,j}$, we delimit the geometrical space where it makes sense to compute (\ref{eq:maximization}) with: 
\begin{equation}
\begin{aligned}
border_{i,j} >= -\varepsilon\\
border_{i,j} <= \varepsilon
\end{aligned} 
\end{equation}
We call such geometrical space the \texttt{tube} between $i$ and $j$.

When \qstatevarmath belongs to the \texttt{tube}, it might be that $u_{i}$ is activated instead of $u_{j}$ (or vice-versa). Otherwise, when \qstatevarmath does not belong to the tube, no matter the error \texttt{err}, the right activation function is activated, and we consider only the error deriving from the computation itself.

Since computing $u_{i}$ introduces approximation error because of finite precision arithmetic, the system has to be robust against an error that is:

\begin{equation}\label{eq:fperror}
err(u_{i})_{p}=|(\hat{F}_{p}-F)\qstatevar+(\hat{G}_{p}-G)|
\end{equation}

where $\hat{F}$ and $\hat{G}$ represent the rounded values (in p bits) for the infinite precision values $F$ and $G$.

In (7) the domain of \qstatevarmath are all the points in region $i$, but also all the values in the \texttt{tube} between region $i$ and any of the neighbors of $i$. Even for values that do not belong to region $i$ it might be the case that $u_{i}$ is (erroneously) activated. In particular, this is true for values in the \texttt{tube}.

We compute (\ref{eq:fperror}) for all regions in \statespace\space and we take the maximum value:

\begin{equation}\label{eq:maxfperror}
\max_{\forall \regionimath{i}\;in\;\statespace} err(u_{i})_{p}
\end{equation}
 

The disturbance \texttt{delta} then has to be an upper bound to the summation of (\ref{eq:maximization}) and (\ref{eq:fperror}).

In formula:
\begin{flalign}
\label{eq:delta}
&delta >= \\
&\max_{\forall i,j\;|\;neighbour(i,j)}|u_{i}-u_{j}| + \max_{\forall\;\regionimath{i}\;in\;\statespace} err(u_{i})_{p}\nonumber
\end{flalign}

\section{Precision Tuning}
In formula (\ref{eq:epsilontot}), the equation for $\varepsilon$ contains: $\varepsilon_{A/D}$ that is the error introduced by the analog-digital conversion, and $\varepsilon_{Q}$ generated by the quantization of hyperplanes H and K in a finite number of bits.
This $\varepsilon_{Q}$ can be tuned based on memory availability in the micro-controller.
The rule for $\varepsilon_{Q}$ is the following:
\begin{equation}\label{eq:quantizationlines}
\varepsilon_{Q} > (H-(\hat{H})_{p})\qstatevar+(K-(\hat{K})_{p})
\end{equation}
This inequality assures that the distance between any hyperplane represented in infinite precision, and the counter-part quantized in p bits, is bounded by $\varepsilon_{Q}$. 

Our goal is to solve (\ref{eq:quantizationlines}) with respect to p: find the minimal-precision for all the coefficients such that the inequality holds.

The main advantage in doing this (compared to fixing the precision a priori), is that the value of p can be tuned based on the memory available in the micro-controller.

To solve (\ref{eq:quantizationlines}) we used Daisy: a static analyzer for both floating-point and fixed-point expressions, able to provide a sound upper-bound to the maximal approximation error of an expression with respect to its real (infinite precision) counterpart. Because the magnitude of the round-off error depends on the range of input variable, all variables encoded in Daisy have to be bounded. 
Since the state variable \statevarmath is bounded, and F,G,H,K are vectors of constants, we can rely on Daisy for this verification step.

In a similar way, we use Daisy to solve the inequality in (\ref{eq:delta}) with respect to p.

\begin{flalign}
\label{eq:deltaminusmax}
&delta - \Big(\max_{\forall i,j\;|\;neighbour(i,j)}|u_{i}-u_{j}|\Big)>=\\
& \max_{\forall\;\regionimath{i}\;in\;\statespace} err(u_{i})_{p}\nonumber
\end{flalign}
We want to point out that the left side of the inequality is not parametrized in p. Only the right size of (\ref{eq:deltaminusmax}) actually depends on the precision p. Again, we encode (\ref{eq:deltaminusmax}) in Daisy to detect what is the minimal precision that still satisfy the inequality.

\section{Algorithm}

\begin{lstlisting}[language=Python,numbers=left,numbersep=3pt,frame=lines,keepspaces=true,escapeinside={(*}{*)},caption=design of robust MPC with verification and precision tuning,label={lst:alg}]
 delta=input()
 (*$\varepsilon_{Q}$*)=input()
 assert (delta>=0 and (*$\varepsilon_{Q}$*)>0)
 epsilon=(*$\varepsilon_{A/D}$*)+(*$\varepsilon_{Q}$*) #size of the tubes

 while True:
   design_robust_MPC(delta)
   maxUij = compute (*(\ref{eq:maximization})*) with size(tube)=(*$\varepsilon$*)
   if delta > maxUij:
     max_err=delta-maxUij
     UNI_MIX_precision(F,G,max_err)
     UNI_MIX_precision(H,K,(*$\varepsilon_{Q}$*))
     break
   else:
     delta=maxUij+(*$\varepsilon_{SAFE}$*)
    
\end{lstlisting}
In Listing \ref{lst:alg} we describe the procedure used to design an MPC controller robust to both (\ref{eq:maximization}) and (\ref{eq:maxfperror}).

First, the designer fixes the initial values for delta and $\varepsilon_{Q}$.

Even if it possible to assign value zero to delta\cite{imperial}, we do not encourage such initialization: it is going to fail the analysis at least once, because the error in (\ref{eq:maxfperror}) is going to be greater than zero (even in case (\ref{eq:maximization}) is zero). A better initialization would be to set delta to an arbitrary small value, slightly greater than zero.

On the other hand, the value for $\varepsilon_{Q}$ has to be strictly greater than zero, otherwise we could rely on infinite precision for p in (\ref{eq:quantizationlines}).

Once input parameters are verified, we use MATLAB toolbox to design a controller with robustness value equal to delta. 

Then, we compute (\ref{eq:maximization}) and we compare the result with delta: we are aware that the computation of (\ref{eq:maximization}) is not exact (even if it is done in 64bits precision), but usually the computation of (\ref{eq:maximization}) results in a value that is several orders of magnitude greater than the error of the computation itself. For this reason we consider this approximation error negligible from the point of view of our analysis. 

Again, in the conditional inside the loop, delta has to be strictly greater than \texttt{maxUij} otherwise we do not have space for computing the precision for (\ref{eq:deltaminusmax}).

In case the conditional is verified,
the precision tuning phase starts.
For the precision tuning of activation functions, we allow an error that is bounded by \texttt{max\_err}. This is because we still need to satisfy (\ref{eq:delta}).
On the other hand, the quantization of polytopes borders (the region bounds in \statespace) can produce an error that is at most $\varepsilon_{Q}$, in this way we satisfy 
(\ref{eq:quantizationlines}).

In case the conditional fails and \texttt{maxUij} is greater than delta, the controller needs to be re-designed with a robustness value that is at least equal to the current value of \texttt{maxUij}. The same consideration done for the initialization values holds also here: the constant $\varepsilon_{SAFE}$ is used to relax the value delta for the controller, to a slight greater value than \texttt{maxUij}. In this way, we aim to give some space to the precision tuning phase in the next iteration of the loop. Otherwise, in case of $\varepsilon_{SAFE}$ equal to zero, the next iteration of the precision tuning phase is going to require unnecessarily wide precision values p, usually greater than 32 bits. 
We remark that the point of the analysis is to find a low precision configuration for bounds and activation functions.
In case the analysis outputs a precision greater than 32bits, we fail in our goal.
Then, with a minimal alteration to the upper bound of delta, we sensibly reduced the precision needed for $F$ and $G$, with respect to the standard 32 bits.

\section{Experimental Results}

\subsection{Case of study: Inverted Pendulum}
%\begin{landscape}
%\begin{table*}[t]
%	\centering
%	\caption{Inverted Pendolum: delta}
%	\label{tab:ipd}
%	\begin{tabular}{r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r}
%		\multicolumn{4}{c}{} &
%		\multicolumn{2}{c}{Xbounds} &
%		\multicolumn{2}{c}{} &
%		\multicolumn{4}{c}{F and G} &
%		\multicolumn{4}{c}{H and K} 
%		\\
%		\multicolumn{1}{c}{delta}&
%		\multicolumn{1}{c}{eps} &
%		\multicolumn{1}{c}{regs} &
%		\multicolumn{1}{c}{hyps} &
%		\multicolumn{1}{c}{X0}&
%		\multicolumn{1}{c}{X1}&
%		\multicolumn{1}{c}{max\_Uij} &
%		\multicolumn{1}{c}{err} &
%		\multicolumn{1}{c}{tot.uni32}&
%		\multicolumn{1}{c}{tot.uni}&
%		\multicolumn{1}{c}{tot.mix}&
%		\multicolumn{1}{c}{\% saved}&
%		\multicolumn{1}{c}{tot.uni32}&
%		\multicolumn{1}{c}{tot.uni}&
%		\multicolumn{1}{c}{tot.mix}&
%		\multicolumn{1}{c}{\% saved}
%		%\multicolumn{1}{c}{\multirow{2}{*}{max|Ui-Uj|}} &
%		%\multicolumn{1}{c}{\multirow{2}{*}{FP\_err}} &
%		%\multicolumn{4}{c}{F and G} &
%		%\multicolumn{4}{c}{H and K} \\
%		%\cline{5-6}\cline{9-12}\cline{13-16} &
%		%\multicolumn{1}{c}{X0}
%		%\multicolumn{1}{c}{X1} &
%		
%	\end{tabular}
%\end{table*}
%\end{landscape}

\subsection{Case of study: 4d example}
\section{Related Work}
\section{Conclusions}

%\begin{table*}
%  \caption{Some Typical Commands}
%  \label{tab:commands}
%  \begin{tabular}{ccl}
%    \toprule
%    Command &A Number & Comments\\
%    \midrule
%    \texttt{{\char'134}author} & 100& Author \\
%    \texttt{{\char'134}table}& 300 & For tables\\
%    \texttt{{\char'134}table*}& 400& For wider tables\\
%    \bottomrule
%  \end{tabular}
%\end{table*}

%\begin{figure}[h]
%  \centering
%  \includegraphics[width=\linewidth]{sample-franklin}
%  \caption{1907 Franklin Model D roadster. Photograph by Harris \& Ewing, Inc. [Public domain], via Wikimedia Commons. (\url{https://goo.gl/VLCRBB}).}
%  \Description{The 1907 Franklin Model D roadster.}
%\end{figure}

%Some examples.  A paginated journal article \cite{Abril07}, an enumerated journal article \cite{Cohen07}, a reference to an entire issue \cite{JCohen96}, a monograph (whole book) \cite{Kosiur01}, a monograph/whole book in a series (see 2a in spec. document)

\bibliographystyle{ACM-Reference-Format}
\bibliography{biblio}

\end{document}
