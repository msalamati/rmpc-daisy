\section{Error Analysis}
\label{sec:Error_Analysis}
\eva{Assuming a given precision, how to compute the error for a given controller}

The output of the controller can be affected by two main errors: (i) the controller chooses the wrong activation function because of imperfect implementation of point location algorithm, and (ii) the approximation error deriving from finite precision arithmetic used to compute the activation function itself~\cite{imperialrmpc}.\\
The disturbance value $\Delta$ has to be an upper bound for the summation of both imprecisions. In formula:
\begin{flalign}
\label{eq:delta}
&\Delta >= \max_{\forall i,j\;|\;neighbour(\mathcal{R}_{i},\mathcal{R}_{j})}|u_{i}-u_{j}| + \max_{\forall i\;|\mathcal{R}_{i}\;in\;\mathcal{R}} err(u_{i})_{p}
\end{flalign}
where $i,j$ are the indexes of two generic regions $\mathcal{R}_{i}$ and $\mathcal{R}_{j}$, \\ $neighbour(\mathcal{R}_{i},\mathcal{R}_{j})$ states when two regions share at least a point (later is defined in details), $u_{i}$ is the activation function for controller $i$ (same for $u_{j}$), $err(u_{i})_{p}$ is the approximation error for computing $u_{i}$ using precision p.

The finite-precision implementation of the point location algorithm introduces some error $\epsilon$ on the top of the exact value of $x_{k}$. Assuming that any point in region $i$ could be erroneously assigned to region $j$, without any  knowledge of the actual magnitude of $\epsilon$, is a too wide over-approximation of the existing instability. 
%In an hypothetic scenario where all the measurements were done in infinite precision arithmetic and without any uncertainty, we assume the controller $i$ would be activated. Instead, because we cannot rely on infinite precision, controller $j$ is selected. 
%The error committed is the difference between the output of the two branches $i$ and $j$.
%The controller has to be robust against a mistake in choosing controller $i$ instead of $j$ (or vice-versa), only when \qstatevarmath falls into the \texttt{tube} between $i$ and $j$, and not for all the points in the two regions. 
There are two main sources of error affecting the magnitude of $\epsilon$: (i) the first one is caused by analog-digital conversion $\varepsilon_{A/D}$
%, happening just before the controller receives an estimation of the plant from the sensors. We call this error $\varepsilon_{A/D}$: 

\begin{equation}\nonumber
\varepsilon_{A/D}=\frac{V_{cc}}{2^{p}-1}
\end{equation}

Where $V_{cc}$ is the reference voltage of the converter (e.g. typical 5V) and $p$ represents the number of bits.

The second error affecting $\epsilon$ is caused by (ii) the quantization of region bounds $\mathcal{R}$ in memory. We call this error $\varepsilon_{Q}$ for error quantization.

While $\varepsilon_{A/D}$ is intrinsic in the capabilities of the device, $\varepsilon_{Q}$ depends on the precision used to store the boundaries. This second error can be tuned based on a trade-off among accuracy of the storage and memory save~\cite{memoryMPC}.
The rule for $\varepsilon_{Q}$ is the following:
\begin{equation}\label{eq:quantizationlines}
\varepsilon_{Q} > (H-\hat{H}_{p})\qstatevar+(K-\hat{K}_{p})
\end{equation}
This inequality assures that the distance between any hyperplane represented in infinite precision (H and K), and its counter-part quantized in p bits ($\hat{H}_{p}$ and $\hat{K}_{p}$), is bounded by $\varepsilon_{Q}$. 

The final formula for $\epsilon$ is then:
\begin{equation}\label{eq:epsilontot}
\varepsilon=\varepsilon_{A/D}+\varepsilon_{Q}
\end{equation}
%\subsection{Finite Precision Implementation}
We use epsilon to build a safe space around the hyperplanes of regions $\mathcal{R}$, such that the maximization function is computed only when \statevarmath follows inside this space among two neighbour regions.
Two regions are neighbors when they share at least a border.

In formula $\exists\; m,n \;$such that:
\begin{equation}
(H_{i}\statevar-K_{j})_{m} = (H_{j}\statevar-K_{j})_{n}
\end{equation}
where $m$ and $n$ are the indexes of the two hyperplanes. We label with $border_{i,j}$ the matching border shared among the two regions.

From the equation of $border_{i,j}$, we delimit the geometrical space where it makes sense to compute the first maximization problem in (\ref{eq:delta}) with the intersection of two half-spaces: 
\begin{equation}\label{eq:tube}
\begin{aligned}
(border_{i,j} >= -\varepsilon) \land
(border_{i,j} <= \varepsilon)
\end{aligned} 
\end{equation}
where $\varepsilon$ is defined in (\ref{eq:epsilontot}). Sometimes later we refer at (\ref{eq:tube}) as the \texttt{tube}, due to its shape for 2D problems. We can easily extend this model to the case when two regions share only a single point.

The effect of selecting the wrong activation function are similar to instability in the switch reported in Listing \ref{lst:caseof}. In case all the arithmetic were exact (infinite precision) and without any uncertainty from hardware measurements, we assume the controller $i$ would be activated. Instead, because of approximation errors, controller $j$ is selected.
In the following, given $i$ and $j$ the index of two generic regions in $\mathcal{R}$:
\begin{flalign}
\label{eq:maximization}
&\max_{\forall i,j\;|\;neighbour(\mathcal{R}_{i},\mathcal{R}_{j})}|u_{i}-u_{j}|=\\
&\max_{\forall i,j\;|\;neighbour(\mathcal{R}_{i},\mathcal{R}_{j})}|F_{i}\statevar+G_{i} - (F_{j}\statevar+G_{j})|\nonumber
\end{flalign}
where \statevarmath satisfies (\ref{eq:tube}) between two regions $i$ and $j$.
%Because of the linearity of the function $u_{i}-u_{j}$, and because of the convexity of the regions $i$ and $j$, it is enough to evaluate function (\ref{eq:maximization}) at the corner points of the \texttt{tube}, instead of solving a maximization problem. 
We compute (\ref{eq:maximization}) for all pairs of neighbor regions $i$ and $j$. 

%When \qstatevarmath belongs to the \texttt{tube}, it might be that $u_{i}$ is activated instead of $u_{j}$ (or vice-versa). Otherwise, when \qstatevarmath does not belong to the tube, no matter the error $\varepsilon$, the right activation function is activated, and we consider only the error deriving from the computation itself.

Since computing $u_{i}$ itself introduces some imprecision because of finite precision arithmetic, the system has to be robust against an error that is:

\begin{equation}\label{eq:fperror}
err(u_{i})_{p}=|(\hat{F}_{p}-F)\statevar+(\hat{G}_{p}-G)|
\end{equation}

where $\hat{F}$ and $\hat{G}$ represent the rounded values (in p bits) for the infinite precision values $F$ and $G$.

In (\ref{eq:fperror}) the domain for \statevarmath are all the points in region $i$, together with all the values in the \texttt{tube} between region $i$ and any of the neighbors of $i$. Even if some points in the tube do not belong to region $i$, it might that $u_{i}$ is (erroneously) activated. We compute (\ref{eq:fperror}) for all regions in $\mathcal{R}$ and we take the maximum value of the error.

%\begin{equation}\label{eq:maxfperror}
%\max_{\forall \regionimath{i}\;in\;\statespace} err(u_{i})_{p}
%\end{equation}